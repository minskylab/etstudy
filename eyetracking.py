# Eye Tracking Study
# This file saves the main class of the dataset generated by

import os
from os import path
import pandas as pd
import tqdm
import numpy as np

"""EyeTrackingStudy is a wrap class to load and use the dataset of the eye tracking study"""


class EyeTrackingStudy:
    def __init__(self, data_path: str = "data"):
        self.data_path = data_path
        self._gazes = None
        self._pupils = None
        self._total_subjects = 0

    @property
    def is_ready(self):
        not_ready = self._gazes is None or self._pupils is None
        return not not_ready

    @is_ready.setter
    def is_ready(self, value):
        self.is_ready = value

    @property
    def gazes(self):
        if not self.is_ready:
            raise "Dataset not initialized"
        return self._gazes

    @gazes.setter
    def gazes(self, value):
        self._gazes = value

    @property
    def pupils(self):
        if not self.is_ready:
            raise "Dataset not initialized"
        return self._pupils

    @pupils.setter
    def pupils(self, value):
        self._pupils = value

    @property
    def subs(self):
        if not self.is_ready:
            raise "Dataset not initialized"
        return self._total_subjects

    @subs.setter
    def subs(self, value):
        self._total_subjects = value

    def gaze_of(self, subject: int):
        if subject < 0 or subject > self._total_subjects-1:
            raise "Invalid subject id"
        if not self.is_ready:
            raise "Dataset not initialized"
        return self.gazes[self.gazes["subject"] == subject]

    def pupil_of(self, subject: int):
        if subject < 0 or subject > self._total_subjects-1:
            raise "Invalid subject id"
        if not self.is_ready:
            raise "Dataset not initialized"
        return self.pupils[self.pupils["subject"] == subject]

    def filter_dataframe(self, df, confidence_th: float = 0.8):
        return df[df["confidence" > confidence_th]]

    def compress(self, df, verbose: bool = True):
        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
        start_mem = df.memory_usage().sum() / 1024**2
        for col in df.columns:
            col_type = df[col].dtypes
            if col_type in numerics:
                c_min = df[col].min()
                c_max = df[col].max()
                if str(col_type)[:3] == 'int':
                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                        df[col] = df[col].astype(np.int8)
                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                        df[col] = df[col].astype(np.int16)
                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                        df[col] = df[col].astype(np.int32)
                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                        df[col] = df[col].astype(np.int64)
                else:
                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                        df[col] = df[col].astype(np.float16)
                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                        df[col] = df[col].astype(np.float32)
                    else:
                        df[col] = df[col].astype(np.float64)
        end_mem = df.memory_usage().sum() / 1024**2
        if verbose:
            print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(
                end_mem, 100 * (start_mem - end_mem) / start_mem))
        return df

    def load_data(self, filtering: bool = False):
        files = os.listdir(self.data_path)

        if len(files) < 3:
            # sum([f.endswith(".csv")  for f in files]):
            if "gazes.csv" in files and "pupils.csv" in files:
                print("loading data from processed dataset")
                gazes_path = path.join(self.data_path, "gazes.csv")
                pupils_path = path.join(self.data_path, "pupils.csv")

                self._gazes = pd.read_csv(gazes_path)
                self._pupils = pd.read_csv(pupils_path)

                self._total_subjects = self._gazes["subject"].nunique()
                return

        print("loading data from raw data")
        # raw data (loaded from eye tracker data)
        subs = 0
        pg = tqdm.tqdm(files)
        for sub in pg:
            if not sub.startswith("sub"):
                continue
            number = int(sub.replace("sub", ""))
            for snap in os.listdir(path.join(self.data_path, sub)):
                if not snap.isnumeric():
                    continue
                current_snapshot = path.join(self.data_path, sub, snap)
                # info = path.join(current_snapshot, "export_info.csv")
                gaze = path.join(current_snapshot, "gaze_positions.csv")
                pupil = path.join(current_snapshot, "pupil_positions.csv")

                gdf = pd.read_csv(gaze)
                if filtering:
                    gdf = self.filter_dataframe(gdf)

                gdf.insert(0, "subject", number)

                if self._gazes is None:
                    self._gazes = gdf
                else:
                    self._gazes = pd.concat((self._gazes, gdf))
                pg.set_description(
                    "Loading gaze data of subject {}".format(number))

                pdf = pd.read_csv(pupil)
                if filtering:
                    pdf = self.filter_dataframe(pdf)

                pdf.insert(0, "subject", number)

                if self._pupils is None:
                    self._pupils = pdf
                else:
                    self._pupils = pd.concat((self._pupils, pdf))
                pg.set_description(
                    "Loading pupil data of subject {}".format(number))
            subs += 1
        self._total_subjects = subs
